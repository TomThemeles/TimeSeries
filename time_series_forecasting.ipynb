{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time Series Forecasting Project\n",
    "\n",
    "This notebook demonstrates various time series forecasting techniques including:\n",
    "- Exploratory Data Analysis (EDA)\n",
    "- ARIMA and SARIMA models\n",
    "- Prophet forecasting\n",
    "- Machine Learning approaches (LSTM)\n",
    "- Model evaluation and comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation and analysis\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Time series analysis\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Deep Learning (if using LSTM)\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "# Prophet (Facebook's forecasting tool)\n",
    "# from prophet import Prophet\n",
    "\n",
    "# Settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Prepare Data\n",
    "\n",
    "For this example, we'll use sample data. You can replace this with your own dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Load from CSV\n",
    "# df = pd.read_csv('your_data.csv', parse_dates=['date_column'], index_col='date_column')\n",
    "\n",
    "# Option 2: Generate sample data\n",
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
    "trend = np.linspace(100, 200, len(date_range))\n",
    "seasonal = 20 * np.sin(2 * np.pi * np.arange(len(date_range)) / 365.25)\n",
    "noise = np.random.normal(0, 10, len(date_range))\n",
    "values = trend + seasonal + noise\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'value': values\n",
    "})\n",
    "df.set_index('date', inplace=True)\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Date range: {df.index.min()} to {df.index.max()}\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics\n",
    "print(\"Summary Statistics:\")\n",
    "print(df.describe())\n",
    "\n",
    "# Check for missing values\n",
    "print(f\"\\nMissing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the time series\n",
    "fig, axes = plt.subplots(2, 1, figsize=(15, 8))\n",
    "\n",
    "# Original series\n",
    "axes[0].plot(df.index, df['value'], linewidth=1)\n",
    "axes[0].set_title('Time Series Data', fontsize=14, fontweight='bold')\n",
    "axes[0].set_xlabel('Date')\n",
    "axes[0].set_ylabel('Value')\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Distribution\n",
    "axes[1].hist(df['value'], bins=50, edgecolor='black', alpha=0.7)\n",
    "axes[1].set_title('Distribution of Values', fontsize=14, fontweight='bold')\n",
    "axes[1].set_xlabel('Value')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Time Series Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decompose the time series into trend, seasonal, and residual components\n",
    "decomposition = seasonal_decompose(df['value'], model='additive', period=365)\n",
    "\n",
    "fig, axes = plt.subplots(4, 1, figsize=(15, 10))\n",
    "\n",
    "decomposition.observed.plot(ax=axes[0], title='Observed', legend=False)\n",
    "axes[0].set_ylabel('Observed')\n",
    "\n",
    "decomposition.trend.plot(ax=axes[1], title='Trend', legend=False)\n",
    "axes[1].set_ylabel('Trend')\n",
    "\n",
    "decomposition.seasonal.plot(ax=axes[2], title='Seasonal', legend=False)\n",
    "axes[2].set_ylabel('Seasonal')\n",
    "\n",
    "decomposition.resid.plot(ax=axes[3], title='Residual', legend=False)\n",
    "axes[3].set_ylabel('Residual')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Stationarity Test\n",
    "\n",
    "Many time series models require the data to be stationary. We'll use the Augmented Dickey-Fuller test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries, title='Time Series'):\n",
    "    \"\"\"\n",
    "    Perform Augmented Dickey-Fuller test for stationarity\n",
    "    \"\"\"\n",
    "    # Rolling statistics\n",
    "    rolling_mean = timeseries.rolling(window=30).mean()\n",
    "    rolling_std = timeseries.rolling(window=30).std()\n",
    "    \n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=(15, 5))\n",
    "    ax.plot(timeseries, label='Original', linewidth=1)\n",
    "    ax.plot(rolling_mean, label='Rolling Mean', linewidth=2)\n",
    "    ax.plot(rolling_std, label='Rolling Std', linewidth=2)\n",
    "    ax.legend()\n",
    "    ax.set_title(f'Rolling Mean & Standard Deviation - {title}')\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # ADF test\n",
    "    print(f'\\nAugmented Dickey-Fuller Test for {title}:')\n",
    "    result = adfuller(timeseries.dropna(), autolag='AIC')\n",
    "    print(f'ADF Statistic: {result[0]:.6f}')\n",
    "    print(f'p-value: {result[1]:.6f}')\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print(f'   {key}: {value:.3f}')\n",
    "    \n",
    "    if result[1] <= 0.05:\n",
    "        print(\"\\n✓ Series is stationary (reject null hypothesis)\")\n",
    "    else:\n",
    "        print(\"\\n✗ Series is non-stationary (fail to reject null hypothesis)\")\n",
    "    \n",
    "    return result[1] <= 0.05\n",
    "\n",
    "test_stationarity(df['value'], 'Original Series')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If non-stationary, apply differencing\n",
    "df['value_diff'] = df['value'].diff()\n",
    "test_stationarity(df['value_diff'].dropna(), 'Differenced Series')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ACF and PACF Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot ACF and PACF to determine ARIMA parameters\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "plot_acf(df['value_diff'].dropna(), lags=40, ax=axes[0])\n",
    "axes[0].set_title('Autocorrelation Function (ACF)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plot_pacf(df['value_diff'].dropna(), lags=40, ax=axes[1])\n",
    "axes[1].set_title('Partial Autocorrelation Function (PACF)', fontsize=14, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "train_size = int(len(df) * 0.8)\n",
    "train_data = df.iloc[:train_size]\n",
    "test_data = df.iloc[train_size:]\n",
    "\n",
    "print(f\"Training set size: {len(train_data)}\")\n",
    "print(f\"Test set size: {len(test_data)}\")\n",
    "print(f\"Train date range: {train_data.index.min()} to {train_data.index.max()}\")\n",
    "print(f\"Test date range: {test_data.index.min()} to {test_data.index.max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. ARIMA Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit ARIMA model\n",
    "# ARIMA(p, d, q) where:\n",
    "# p = number of autoregressive terms\n",
    "# d = number of differences\n",
    "# q = number of moving average terms\n",
    "\n",
    "order = (2, 1, 2)  # Adjust based on ACF/PACF analysis\n",
    "arima_model = ARIMA(train_data['value'], order=order)\n",
    "arima_result = arima_model.fit()\n",
    "\n",
    "print(arima_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "arima_forecast = arima_result.forecast(steps=len(test_data))\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data['value'], label='Training Data', linewidth=1)\n",
    "plt.plot(test_data.index, test_data['value'], label='Actual Test Data', linewidth=1)\n",
    "plt.plot(test_data.index, arima_forecast, label='ARIMA Forecast', linewidth=2, linestyle='--')\n",
    "plt.title('ARIMA Model Forecast', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics\n",
    "arima_mse = mean_squared_error(test_data['value'], arima_forecast)\n",
    "arima_rmse = np.sqrt(arima_mse)\n",
    "arima_mae = mean_absolute_error(test_data['value'], arima_forecast)\n",
    "\n",
    "print(f\"\\nARIMA Model Performance:\")\n",
    "print(f\"RMSE: {arima_rmse:.4f}\")\n",
    "print(f\"MAE: {arima_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SARIMA Model (Seasonal ARIMA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit SARIMA model\n",
    "# SARIMA(p, d, q)(P, D, Q, s) where:\n",
    "# (p, d, q) = non-seasonal parameters\n",
    "# (P, D, Q, s) = seasonal parameters, s = seasonal period\n",
    "\n",
    "order = (2, 1, 2)\n",
    "seasonal_order = (1, 1, 1, 365)  # Daily data with yearly seasonality\n",
    "\n",
    "sarima_model = SARIMAX(train_data['value'], \n",
    "                       order=order, \n",
    "                       seasonal_order=seasonal_order,\n",
    "                       enforce_stationarity=False,\n",
    "                       enforce_invertibility=False)\n",
    "sarima_result = sarima_model.fit(disp=False)\n",
    "\n",
    "print(sarima_result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "sarima_forecast = sarima_result.forecast(steps=len(test_data))\n",
    "\n",
    "# Visualize results\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(train_data.index, train_data['value'], label='Training Data', linewidth=1)\n",
    "plt.plot(test_data.index, test_data['value'], label='Actual Test Data', linewidth=1)\n",
    "plt.plot(test_data.index, sarima_forecast, label='SARIMA Forecast', linewidth=2, linestyle='--')\n",
    "plt.title('SARIMA Model Forecast', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate metrics\n",
    "sarima_mse = mean_squared_error(test_data['value'], sarima_forecast)\n",
    "sarima_rmse = np.sqrt(sarima_mse)\n",
    "sarima_mae = mean_absolute_error(test_data['value'], sarima_forecast)\n",
    "\n",
    "print(f\"\\nSARIMA Model Performance:\")\n",
    "print(f\"RMSE: {sarima_rmse:.4f}\")\n",
    "print(f\"MAE: {sarima_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Prophet Model (Optional)\n",
    "\n",
    "Uncomment and install Prophet if you want to use it:\n",
    "```bash\n",
    "pip install prophet\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare data for Prophet (requires 'ds' and 'y' columns)\n",
    "# prophet_train = train_data.reset_index()\n",
    "# prophet_train.columns = ['ds', 'y']\n",
    "# \n",
    "# # Fit Prophet model\n",
    "# prophet_model = Prophet(\n",
    "#     yearly_seasonality=True,\n",
    "#     weekly_seasonality=True,\n",
    "#     daily_seasonality=False,\n",
    "#     changepoint_prior_scale=0.05\n",
    "# )\n",
    "# prophet_model.fit(prophet_train)\n",
    "# \n",
    "# # Make predictions\n",
    "# future = prophet_model.make_future_dataframe(periods=len(test_data), freq='D')\n",
    "# prophet_forecast = prophet_model.predict(future)\n",
    "# \n",
    "# # Visualize\n",
    "# fig = prophet_model.plot(prophet_forecast)\n",
    "# plt.title('Prophet Model Forecast', fontsize=14, fontweight='bold')\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# \n",
    "# # Component analysis\n",
    "# fig = prophet_model.plot_components(prophet_forecast)\n",
    "# plt.tight_layout()\n",
    "# plt.show()\n",
    "# \n",
    "# # Calculate metrics\n",
    "# prophet_predictions = prophet_forecast.iloc[-len(test_data):]['yhat'].values\n",
    "# prophet_rmse = np.sqrt(mean_squared_error(test_data['value'], prophet_predictions))\n",
    "# prophet_mae = mean_absolute_error(test_data['value'], prophet_predictions)\n",
    "# \n",
    "# print(f\"\\nProphet Model Performance:\")\n",
    "# print(f\"RMSE: {prophet_rmse:.4f}\")\n",
    "# print(f\"MAE: {prophet_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. LSTM Model (Optional)\n",
    "\n",
    "Uncomment and install TensorFlow/Keras if you want to use LSTM:\n",
    "```bash\n",
    "pip install tensorflow\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Prepare data for LSTM\n",
    "# def create_sequences(data, seq_length):\n",
    "#     X, y = [], []\n",
    "#     for i in range(len(data) - seq_length):\n",
    "#         X.append(data[i:i+seq_length])\n",
    "#         y.append(data[i+seq_length])\n",
    "#     return np.array(X), np.array(y)\n",
    "# \n",
    "# # Scale data\n",
    "# scaler = MinMaxScaler()\n",
    "# scaled_data = scaler.fit_transform(df['value'].values.reshape(-1, 1))\n",
    "# \n",
    "# # Create sequences\n",
    "# seq_length = 30\n",
    "# X, y = create_sequences(scaled_data, seq_length)\n",
    "# \n",
    "# # Split into train and test\n",
    "# train_size = int(len(X) * 0.8)\n",
    "# X_train, X_test = X[:train_size], X[train_size:]\n",
    "# y_train, y_test = y[:train_size], y[train_size:]\n",
    "# \n",
    "# # Build LSTM model\n",
    "# lstm_model = Sequential([\n",
    "#     LSTM(50, activation='relu', return_sequences=True, input_shape=(seq_length, 1)),\n",
    "#     Dropout(0.2),\n",
    "#     LSTM(50, activation='relu'),\n",
    "#     Dropout(0.2),\n",
    "#     Dense(1)\n",
    "# ])\n",
    "# \n",
    "# lstm_model.compile(optimizer='adam', loss='mse')\n",
    "# \n",
    "# # Train model\n",
    "# history = lstm_model.fit(\n",
    "#     X_train, y_train,\n",
    "#     epochs=50,\n",
    "#     batch_size=32,\n",
    "#     validation_split=0.1,\n",
    "#     verbose=1\n",
    "# )\n",
    "# \n",
    "# # Make predictions\n",
    "# lstm_predictions = lstm_model.predict(X_test)\n",
    "# lstm_predictions = scaler.inverse_transform(lstm_predictions)\n",
    "# y_test_actual = scaler.inverse_transform(y_test)\n",
    "# \n",
    "# # Calculate metrics\n",
    "# lstm_rmse = np.sqrt(mean_squared_error(y_test_actual, lstm_predictions))\n",
    "# lstm_mae = mean_absolute_error(y_test_actual, lstm_predictions)\n",
    "# \n",
    "# print(f\"\\nLSTM Model Performance:\")\n",
    "# print(f\"RMSE: {lstm_rmse:.4f}\")\n",
    "# print(f\"MAE: {lstm_mae:.4f}\")\n",
    "# \n",
    "# # Plot results\n",
    "# plt.figure(figsize=(15, 6))\n",
    "# plt.plot(y_test_actual, label='Actual', linewidth=1)\n",
    "# plt.plot(lstm_predictions, label='LSTM Forecast', linewidth=2, linestyle='--')\n",
    "# plt.title('LSTM Model Forecast', fontsize=14, fontweight='bold')\n",
    "# plt.xlabel('Time Steps')\n",
    "# plt.ylabel('Value')\n",
    "# plt.legend()\n",
    "# plt.grid(True, alpha=0.3)\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare all models\n",
    "results_df = pd.DataFrame({\n",
    "    'Model': ['ARIMA', 'SARIMA'],\n",
    "    'RMSE': [arima_rmse, sarima_rmse],\n",
    "    'MAE': [arima_mae, sarima_mae]\n",
    "})\n",
    "\n",
    "# Add Prophet and LSTM if used\n",
    "# results_df = results_df.append({'Model': 'Prophet', 'RMSE': prophet_rmse, 'MAE': prophet_mae}, ignore_index=True)\n",
    "# results_df = results_df.append({'Model': 'LSTM', 'RMSE': lstm_rmse, 'MAE': lstm_mae}, ignore_index=True)\n",
    "\n",
    "print(\"\\nModel Comparison:\")\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Visualize comparison\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "results_df.plot(x='Model', y='RMSE', kind='bar', ax=axes[0], legend=False, color='steelblue')\n",
    "axes[0].set_title('RMSE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[0].set_ylabel('RMSE')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "results_df.plot(x='Model', y='MAE', kind='bar', ax=axes[1], legend=False, color='coral')\n",
    "axes[1].set_title('MAE Comparison', fontsize=14, fontweight='bold')\n",
    "axes[1].set_ylabel('MAE')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Residual Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze residuals for the best model (using SARIMA as example)\n",
    "residuals = test_data['value'].values - sarima_forecast.values\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# Residuals over time\n",
    "axes[0, 0].plot(test_data.index, residuals, linewidth=1)\n",
    "axes[0, 0].axhline(y=0, color='r', linestyle='--')\n",
    "axes[0, 0].set_title('Residuals Over Time', fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('Date')\n",
    "axes[0, 0].set_ylabel('Residual')\n",
    "axes[0, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "axes[0, 1].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 1].set_title('Distribution of Residuals', fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('Residual')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "axes[0, 1].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1, 0])\n",
    "axes[1, 0].set_title('Q-Q Plot', fontsize=12, fontweight='bold')\n",
    "axes[1, 0].grid(True, alpha=0.3)\n",
    "\n",
    "# ACF of residuals\n",
    "plot_acf(residuals, lags=30, ax=axes[1, 1])\n",
    "axes[1, 1].set_title('ACF of Residuals', fontsize=12, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"Mean: {np.mean(residuals):.4f}\")\n",
    "print(f\"Std Dev: {np.std(residuals):.4f}\")\n",
    "print(f\"Min: {np.min(residuals):.4f}\")\n",
    "print(f\"Max: {np.max(residuals):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Future Forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make future predictions (e.g., next 90 days)\n",
    "future_steps = 90\n",
    "\n",
    "# Retrain on full dataset\n",
    "final_model = SARIMAX(df['value'], \n",
    "                      order=order, \n",
    "                      seasonal_order=seasonal_order,\n",
    "                      enforce_stationarity=False,\n",
    "                      enforce_invertibility=False)\n",
    "final_result = final_model.fit(disp=False)\n",
    "\n",
    "# Forecast\n",
    "future_forecast = final_result.forecast(steps=future_steps)\n",
    "future_dates = pd.date_range(start=df.index[-1] + pd.Timedelta(days=1), periods=future_steps, freq='D')\n",
    "\n",
    "# Get confidence intervals\n",
    "forecast_object = final_result.get_forecast(steps=future_steps)\n",
    "confidence_intervals = forecast_object.conf_int()\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(df.index, df['value'], label='Historical Data', linewidth=1)\n",
    "plt.plot(future_dates, future_forecast, label='Future Forecast', linewidth=2, linestyle='--', color='red')\n",
    "plt.fill_between(future_dates, \n",
    "                 confidence_intervals.iloc[:, 0], \n",
    "                 confidence_intervals.iloc[:, 1], \n",
    "                 alpha=0.2, color='red', label='95% Confidence Interval')\n",
    "plt.title('Future Forecast with Confidence Intervals', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Value')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Display forecast table\n",
    "forecast_df = pd.DataFrame({\n",
    "    'Date': future_dates,\n",
    "    'Forecast': future_forecast.values,\n",
    "    'Lower CI': confidence_intervals.iloc[:, 0].values,\n",
    "    'Upper CI': confidence_intervals.iloc[:, 1].values\n",
    "})\n",
    "\n",
    "print(\"\\nFuture Forecast (first 10 days):\")\n",
    "print(forecast_df.head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Conclusions and Recommendations\n",
    "\n",
    "Based on the analysis:\n",
    "\n",
    "1. **Model Performance**: Compare RMSE and MAE values to select the best performing model\n",
    "2. **Seasonality**: The data shows clear seasonal patterns that SARIMA captures well\n",
    "3. **Residuals**: Check if residuals are normally distributed and uncorrelated\n",
    "4. **Future Work**: \n",
    "   - Experiment with different hyperparameters\n",
    "   - Try ensemble methods combining multiple models\n",
    "   - Incorporate external variables if available\n",
    "   - Use cross-validation for robust evaluation\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. Replace sample data with your actual time series data\n",
    "2. Adjust model parameters based on your data characteristics\n",
    "3. Experiment with additional models (Prophet, LSTM, etc.)\n",
    "4. Fine-tune the best performing model\n",
    "5. Deploy the model for production forecasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final model (optional)\n",
    "# import joblib\n",
    "# joblib.dump(final_result, 'time_series_model.pkl')\n",
    "# print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
